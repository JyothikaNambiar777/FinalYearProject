# FinalYearProject
Orchestrating Consensus Strategies and Zero-Sum Game to Counter AI Hallucination in Chatbot Ecosystems

![image](https://github.com/JyothikaNambiar777/FinalYearProject/assets/82314985/c838a5f5-28c8-4ce2-81c8-218e76b5dbe3)

AI hallucination refers to the phenomenon where AI models, such as chatbots, generate inaccurate or fabricated information that appears plausible to users. For example, medical chatbots fabricate their response and give false positives or false negatives instead of the actual results for research or a diagnosis.  This can undermine the reliability, trustworthiness, and overall quality of interactions in chatbot ecosystems, which can have significant consequences, especially in critical domains where accuracy is crucial. The proposed solution is to use a multitude of chatbots to come to a consensus about their responses. 




